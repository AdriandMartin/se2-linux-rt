cpus=1
# tracer: wakeup
#
# wakeup latency trace v1.1.5 on 3.8.13-rt14
# --------------------------------------------------------------------
# latency: 529 us, #194/194, CPU#0 | (M:preempt VP:0, KP:0, SP:0 HP:0 #P:1)
#    -----------------
#    | task: kworker/0:1H-86 (uid:0 nice:-20 policy:0 rt_prio:0)
#    -----------------
#
#                   _--------=> CPU#              
#                  / _-------=> irqs-off          
#                 | / _------=> need-resched      
#                 || / _-----=> need-resched_lazy 
#                 ||| / _----=> hardirq/softirq   
#                 |||| / _---=> preempt-depth     
#                 ||||| / _--=> preempt-lazy-depth
#                 |||||| / _-=> migrate-disable   
#                 ||||||| /     delay             
#  cmd     pid    |||||||| time  |   caller       
#     \   /      ||||||||  \   |   /            
 mmcqd/0-65      0d...314    1us+:     65:120:R   + [000]    86:100:R kworker/0:1H
 mmcqd/0-65      0d...314    4us+: 0
 mmcqd/0-65      0d...314    6us+: check_preempt_curr <-ttwu_do_wakeup
 mmcqd/0-65      0d...314    8us+: check_preempt_wakeup <-check_preempt_curr
 mmcqd/0-65      0d...314   10us+: update_curr <-check_preempt_wakeup
 mmcqd/0-65      0d...314   12us+: wakeup_preempt_entity <-check_preempt_wakeup
 mmcqd/0-65      0d...314   14us+: calc_delta_mine <-wakeup_preempt_entity
 mmcqd/0-65      0d...314   17us+: set_next_buddy <-check_preempt_wakeup
 mmcqd/0-65      0d...314   19us+: resched_task_lazy <-check_preempt_wakeup
 mmcqd/0-65      0d.L.314   21us+: _raw_spin_unlock <-try_to_wake_up
 mmcqd/0-65      0d.L.314   24us+: sub_preempt_count <-_raw_spin_unlock
 mmcqd/0-65      0d.L.214   26us+: ttwu_stat <-try_to_wake_up
 mmcqd/0-65      0d.L.214   28us+: _raw_spin_unlock_irqrestore <-try_to_wake_up
 mmcqd/0-65      0..L.214   30us+: sub_preempt_count <-_raw_spin_unlock_irqrestore
 mmcqd/0-65      0..L.114   33us+: rt_spin_unlock <-__queue_work
 mmcqd/0-65      0..L.114   35us+: rt_spin_lock_slowunlock <-__queue_work
 mmcqd/0-65      0..L.114   37us+: _raw_spin_lock <-rt_spin_lock_slowunlock
 mmcqd/0-65      0..L.114   39us+: add_preempt_count <-_raw_spin_lock
 mmcqd/0-65      0..L.214   41us+: _raw_spin_unlock <-__queue_work
 mmcqd/0-65      0..L.214   43us+: sub_preempt_count <-_raw_spin_unlock
 mmcqd/0-65      0..L.114   45us+: migrate_enable <-queue_work_on
 mmcqd/0-65      0..L.114   47us+: add_preempt_count <-migrate_enable
 mmcqd/0-65      0..L.213   49us+: sub_preempt_count <-migrate_enable
 mmcqd/0-65      0..L.113   52us+: rt_spin_unlock <-queue_work_on
 mmcqd/0-65      0..L.113   54us+: rt_spin_lock_slowunlock <-queue_work_on
 mmcqd/0-65      0..L.113   56us+: _raw_spin_lock <-rt_spin_lock_slowunlock
 mmcqd/0-65      0..L.113   58us+: add_preempt_count <-_raw_spin_lock
 mmcqd/0-65      0..L.213   60us+: _raw_spin_unlock <-queue_work_on
 mmcqd/0-65      0..L.213   62us+: sub_preempt_count <-_raw_spin_unlock
