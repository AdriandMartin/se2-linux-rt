cpus=1
# tracer: wakeup
#
# wakeup latency trace v1.1.5 on 3.8.13-rt14
# --------------------------------------------------------------------
# latency: 861 us, #4294952383/4294952383, CPU#0 | (M:preempt VP:0, KP:0, SP:0 HP:0 #P:1)
#    -----------------
#    | task: kworker/0:1H-86 (uid:0 nice:-20 policy:0 rt_prio:0)
#    -----------------
#
#                   _--------=> CPU#              
#                  / _-------=> irqs-off          
#                 | / _------=> need-resched      
#                 || / _-----=> need-resched_lazy 
#                 ||| / _----=> hardirq/softirq   
#                 |||| / _---=> preempt-depth     
#                 ||||| / _--=> preempt-lazy-depth
#                 |||||| / _-=> migrate-disable   
#                 ||||||| /     delay             
#  cmd     pid    |||||||| time  |   caller       
#     \   /      ||||||||  \   |   /            
 mmcqd/0-65      0d...314    1us+:     65:120:R   + [000]    86:100:R kworker/0:1H
 mmcqd/0-65      0d...314    5us+: 0
 mmcqd/0-65      0d...314    7us+: check_preempt_curr <-ttwu_do_wakeup
 mmcqd/0-65      0d...314    9us+: check_preempt_wakeup <-check_preempt_curr
 mmcqd/0-65      0d...314   11us+: update_curr <-check_preempt_wakeup
 mmcqd/0-65      0d...314   13us+: wakeup_preempt_entity <-check_preempt_wakeup
 mmcqd/0-65      0d...314   15us+: calc_delta_mine <-wakeup_preempt_entity
 mmcqd/0-65      0d...314   18us+: set_next_buddy <-check_preempt_wakeup
 mmcqd/0-65      0d...314   20us+: resched_task_lazy <-check_preempt_wakeup
 mmcqd/0-65      0d.L.314   22us+: _raw_spin_unlock <-try_to_wake_up
 mmcqd/0-65      0d.L.314   25us+: sub_preempt_count <-_raw_spin_unlock
 mmcqd/0-65      0d.L.214   27us+: ttwu_stat <-try_to_wake_up
 mmcqd/0-65      0d.L.214   30us+: _raw_spin_unlock_irqrestore <-try_to_wake_up
 mmcqd/0-65      0..L.214   32us+: sub_preempt_count <-_raw_spin_unlock_irqrestore
 mmcqd/0-65      0..L.114   34us+: rt_spin_unlock <-__queue_work
 mmcqd/0-65      0..L.114   37us+: rt_spin_lock_slowunlock <-__queue_work
 mmcqd/0-65      0..L.114   39us+: _raw_spin_lock <-rt_spin_lock_slowunlock
 mmcqd/0-65      0..L.114   41us+: add_preempt_count <-_raw_spin_lock
 mmcqd/0-65      0..L.214   43us+: _raw_spin_unlock <-__queue_work
 mmcqd/0-65      0..L.214   45us+: sub_preempt_count <-_raw_spin_unlock
 mmcqd/0-65      0..L.114   48us+: migrate_enable <-queue_work_on
 mmcqd/0-65      0..L.114   49us+: add_preempt_count <-migrate_enable
 mmcqd/0-65      0..L.213   52us+: sub_preempt_count <-migrate_enable
 mmcqd/0-65      0..L.113   54us+: rt_spin_unlock <-queue_work_on
 mmcqd/0-65      0..L.113   56us+: rt_spin_lock_slowunlock <-queue_work_on
 mmcqd/0-65      0..L.113   58us+: _raw_spin_lock <-rt_spin_lock_slowunlock
 mmcqd/0-65      0..L.113   60us+: add_preempt_count <-_raw_spin_lock
 mmcqd/0-65      0..L.213   62us+: _raw_spin_unlock <-queue_work_on
 mmcqd/0-65      0..L.213   64us+: sub_preempt_count <-_raw_spin_unlock
